МІНІСТЕРСТВО ОСВІТИ І НАУКИ УКРАЇНИ
ХАРКІВСЬКИЙ НАЦІОНАЛЬНИЙ УНІВЕРСИТЕТ РАДІОЕЛЕКТРОНІКИ


ФАКУЛЬТЕТ КОМП’ЮТЕРНИХ НАУК
КАТЕДРА ПРОГРАМНОЇ ІНЖЕНЕРІЇ








ЗВІТ
до лабораторної роботи №5 з дисципліни
«Аналіз та рефакторинґ коду»
на тему: «РОЗГОРТАННЯ ПРОГРАМНОЇ СИСТЕМИ ТА ДЕМОНСТРАЦІЯ ЇЇ РОБОТИ»








Виконав:                                                                                                  Перевірив:
ст. гр. ПЗПІ-23-6                                                                      ас. катедри ПІ
Ананьєв Несторіан Сергійович                        Дашенков Дмитро Сергійович






Харків 2025




1 ЗАВДАННЯ


Розгорнути програмну систему GPS-трекінгу на production середовищі та продемонструвати її роботу. Система включає серверну частину на базі NestJS, MQTT брокер EMQX для обробки IoT телеметрії, базу даних PostgreSQL, Redis для кешування активних рейсів, та IoT клієнти на мікроконтролерах ESP32.




________________


2 ОПИС ВИКОНАНОЇ РОБОТИ
2.1. Інфраструктура розгортання
Система розгорнута на VPS сервері DigitalOcean з операційною системою Ubuntu 24.04 LTS, 2 GB оперативної пам'яті та 50 GB дискового простору. Для організації інфраструктури використано контейнеризацію Docker, що дозволяє ізолювати компоненти системи та спростити процес deployment. Архітектура складається з п'яти основних сервісів: PostgreSQL 16 для зберігання реляційних даних, Redis 7 для кешування інформації про активні рейси, EMQX 5.8 як MQTT брокер для комунікації з IoT пристроями, backend додаток на NestJS з REST API та бізнес-логікою, а також IoT клієнти на базі ESP32 які виступають як GPS-трекери з автономною роботою.
Для зручності доступу до системи зареєстровано доменне ім'я orionix-track.pp.ua через український реєстратор NIC.UA. Налаштовано reverse proxy через Nginx для маршрутизації HTTP трафіку до backend контейнера. За допомогою утиліти Certbot від Let's Encrypt отримано безкоштовні SSL сертифікати, що забезпечують шифроване HTTPS з'єднання. REST API документація доступна за адресою https://api.orionix-track.pp.ua/docs з автоматично згенерованою Swagger специфікацією. Використання власного домену та SSL сертифікатів підвищує рівень безпеки системи та спрощує інтеграцію з клієнтськими додатками.


2.2. Автоматизація розгортання
Процес розгортання повністю автоматизовано через GitHub Actions CI/CD pipeline. При кожному push коду до гілки main автоматично запускається двоетапний процес: спочатку виконується збірка Docker образу backend додатку та його публікація в GitHub Container Registry, а потім здійснюється deployment на VPS сервер через SSH підключення. Використання GitHub Container Registry дозволяє централізовано зберігати версії образів та швидко доставляти їх на production сервер.


deploy:
 name: Deploy to VPS
 runs-on: ubuntu-latest
 needs: build-and-push
 steps:
   - name: Deploy to VPS via SSH
     uses: appleboy/ssh-action@v1.0.3
     with:
       host: ${{ secrets.VPS_HOST }}
       username: ${{ secrets.VPS_USER }}
       key: ${{ secrets.VPS_SSH_KEY }}
       script: |
         cd /opt/orionix-track
        docker compose pull backend
        docker compose up -d --no-build
        docker image prune -af


Deployment скрипт підключається до VPS через SSH з використанням криптографічних ключів, завантажує нову версію backend образу через команду docker compose pull, перезапускає оновлені контейнери без зупинки інших сервісів, та очищає старі невикористовувані образи для економії дискового простору. Такий підхід забезпечує мінімальний downtime при оновленні системи та дозволяє швидко відкотитися до попередньої версії у разі виявлення критичних помилок.


2.3. Docker Compose конфігурація


Всі компоненти системи описані в декларативному форматі Docker Compose, що дозволяє керувати інфраструктурою як кодом. Конфігурація включає визначення сервісів PostgreSQL з персистентним volume для збереження даних бази, Redis з власним volume для RDB snapshots, EMQX з експозицією портів для MQTT протоколу та веб-дашборду, та backend сервіс який залежить від готовності всіх інших компонентів. Кожен сервіс має налаштований healthcheck для автоматичного моніторингу стану: PostgreSQL перевіряється через pg_isready команду, Redis через redis-cli ping, а EMQX через вбудовану команду emqx ctl status.


services:
 postgres:
   image: postgres:16-alpine
   volumes:
     - postgres_data:/var/lib/postgresql/data
   healthcheck:
     test: ['CMD-SHELL', 'pg_isready']
     interval: 10s


 redis:
   image: redis:7-alpine
   volumes:
     - redis_data:/data


 emqx:
   image: emqx/emqx:5.8
   ports:
     - '1883:1883'
     - '18083:18083'
   volumes:
     - emqx_data:/opt/emqx/data


 backend:
   image: ghcr.io/${GITHUB_REPOSITORY}:latest
   depends_on:
     postgres:
       condition: service_healthy
     redis:
       condition: service_healthy
     emqx:
       condition: service_healthy
   ports:
     - '3000:3000'
   command: sh -c "npm run migration:run && node dist/main.js"


Backend контейнер запускається тільки після того як всі залежні сервіси пройшли healthcheck та готові приймати з'єднання. При старті backend автоматично виконуються міграції бази даних через TypeORM CLI, що забезпечує синхронізацію схеми бази з актуальною версією коду. Використання іменованих volumes для PostgreSQL, Redis та EMQX гарантує збереження всіх даних при перезапуску або оновленні контейнерів.


2.4. Налаштування IoT клієнтів
ESP32 трекери налаштовуються через вбудований веб-портал на базі бібліотеки WiFiManager. При першому запуску пристрій не маючи збереженої конфігурації WiFi автоматично створює власну точку доступу з SSID "GPS-TRACKER-AP". Користувач підключається до цієї мережі з будь-якого смартфона або ноутбука та отримує доступ до веб-інтерфейсу конфігурації за адресою 192.168.4.1. Через інтуїтивний веб-форм вводяться всі необхідні параметри: SSID та пароль домашньої або корпоративної WiFi мережі, IP адреса або доменне ім'я MQTT брокера, порт для підключення, унікальний ідентифікатор пристрою та токен автентифікації згенерований в backend системі.
Після збереження конфігурації всі параметри записуються в енергонезалежну NVS пам'ять ESP32, що забезпечує їх збереження навіть при повному знеструмленні пристрою. Трекер автоматично перезавантажується та підключається до вказаної WiFi мережі, після чого встановлює MQTT з'єднання з брокером використовуючи збережені credentials. На серверній частині трекер повинен бути попередньо зареєстрований через REST API з створенням запису в таблиці trackers та прив'язкою до конкретного транспортного засобу. Система підтримує можливість повторного входу в режим конфігурації через натискання апаратної кнопки на GPIO0, що дозволяє змінити параметри без перепрошивки firmware.
________________


ВИСНОВКИ
У ході виконання лабораторної роботи успішно розгорнуто повнофункціональну IoT систему GPS-трекінгу на production VPS сервері з використанням контейнеризації Docker. Реалізовано повну автоматизацію процесу deployment через GitHub Actions CI/CD pipeline, що дозволяє оновлювати систему без ручного втручання та мінімізує ризики людських помилок. Налаштовано власний домен з SSL сертифікатами для забезпечення безпечного доступу до REST API через HTTPS протокол.
Система демонструє всі ключові функції включаючи автоматичне налаштування IoT клієнтів через WiFi портал, обробку телеметрії в реальному часі через MQTT протокол, механізм офлайн-кешування з автоматичним відновленням даних при reconnect, та рольову модель доступу для адміністрування серверної частини. Використання Docker Compose забезпечує просте керування всіма компонентами системи як єдиною інфраструктурою та дає можливість горизонтального масштабування при зростанні навантаження.
Репозиторій на GitHub: https://github.com/OrionixTrack/iot-gps-tracker 
API документація: https://api.orionix-track.pp.ua/docs